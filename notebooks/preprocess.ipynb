{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import cPickle as pickle\n",
    "from attrdict import AttrDict\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "import cv2\n",
    "\n",
    "from tensorflow.python.util import nest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# indices to columns of the ground-truth matrix\n",
    "key = 'camera ID frame left top width height worldX worldY feetX feetyY'.split()\n",
    "key = {k: v for v, k in enumerate(key)}\n",
    "\n",
    "# cameras are synshcornised with respect to camera #5 and these are frame offsets\n",
    "start_frame_nums = [5543, 3607, 27244, 31182, 1, 22402, 18968, 46766]\n",
    "\n",
    "# the dataset will be composed of sequences of this length\n",
    "target_sequence_length = 10\n",
    "\n",
    "# num pixels in the longer side of the original videos\n",
    "original_longer = 1920\n",
    "\n",
    "# relative path to the folder with all frames\n",
    "frames_folder = 'frames'\n",
    "seqs_folder = 'fancy_seqs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path to the ground-truth file\n",
    "gt_path = '../trainvalRaw.mat'\n",
    "# path = '../trainval.mat'\n",
    "\n",
    "# path to the folder with extracted frames\n",
    "data_path = '../processed/camera2_240'\n",
    "\n",
    "\n",
    "# num pixels in the longer side of downscaled videos\n",
    "downscaled_longer = 240\n",
    "\n",
    "# region of interest as y, x, h, w in the downscaled image\n",
    "# roi = 13, 48, 64, 64\n",
    "# roi = 60, 90, 64, 64\n",
    "\n",
    "roi_size = 64, 64\n",
    "roi = None\n",
    "\n",
    "\n",
    "# the final dataset will be written to this file\n",
    "pickle_path = 'duke_cam_2_240_roi_{}_t_10.pickle'\n",
    "\n",
    "camera_num = 2\n",
    "max_n_objects = 3\n",
    "\n",
    "\n",
    "\n",
    "# fraction of object that needs to be within the roi to be counted as present\n",
    "intersection_threshold = .25\n",
    "assert 0. <= intersection_threshold <= 1.\n",
    "\n",
    "# maximum allowed number of consecutive empty frames in a sequence\n",
    "max_empty_frames = 2\n",
    "\n",
    "# minimum sequence length\n",
    "min_seq_len = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if roi is None:\n",
    "    u = np.random.uniform(size=2)\n",
    "    bounds = np.asarray([downscaled_longer * 2./3, downscaled_longer]) - roi_size\n",
    "    yx = np.round(bounds * u).astype(np.int32)\n",
    "    roi = tuple(yx) + roi_size\n",
    "    print 'roi =', roi\n",
    "\n",
    "ratio = float(original_longer) / downscaled_longer\n",
    "original_roi = ratio * np.asarray(roi)\n",
    "start_frame_num = start_frame_nums[camera_num - 1]\n",
    "\n",
    "frames_folder = os.path.join(data_path, frames_folder)\n",
    "seqs_folder = os.path.join(data_path, seqs_folder)\n",
    "pickle_path = os.path.join(data_path, pickle_path.format('_'.join([str(s) for s in roi])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'Loading \"{}\"'.format(os.path.basename(gt_path))\n",
    "\n",
    "if 'Raw' in gt_path:\n",
    "    import h5py\n",
    "    f = h5py.File(gt_path, 'r')\n",
    "    data = f['trainData'][()].T\n",
    "else:\n",
    "    import scipy.io\n",
    "    f = scipy.io.loadmat(gt_path)\n",
    "    data = f['trainData']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select data for the specified camera and shift frame nums by the starting frame num\n",
    "camera_idx = np.equal(data[:, 0], camera_num)\n",
    "frames, left, top, width, height = np.split(data[camera_idx, 2:7], 5, -1)\n",
    "\n",
    "boxes = np.concatenate([top, left, height, width], -1)\n",
    "# frames -= start_frame_num\n",
    "\n",
    "objects = np.concatenate([frames, boxes], -1) # frame, bbox\n",
    "\n",
    "print 'Total number of objects:', objects.shape[0]\n",
    "print 'Frames from {} to {}'.format(frames.min(), frames.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select objects that are only withing the region of interest\n",
    "def intersection(bbox, roi):\n",
    "    \"\"\"Computes area of intersection between boxes in `bbox` and boxes in `roi`.\n",
    "    Dimensions in both should be given as (y, x, h, w).\n",
    "\n",
    "    :param bbox: np.array of shape [N, 4]\n",
    "    :param roi: np.array of shape [4] or [k, 4] where k \\in {1, N}\n",
    "    :return: np.array of shape [N]\n",
    "    \"\"\"\n",
    "\n",
    "    bbox = np.asarray(bbox)\n",
    "    roi = np.asarray(roi)\n",
    "\n",
    "    while len(roi.shape) < len(bbox.shape):\n",
    "        roi = roi[np.newaxis, ...]\n",
    "\n",
    "    y_top = np.maximum(bbox[..., 0], roi[..., 0])\n",
    "    x_left = np.maximum(bbox[..., 1], roi[..., 1])\n",
    "    y_bottom = np.minimum(bbox[..., 0] + bbox[..., 2], roi[..., 0] + roi[..., 2])\n",
    "    x_right = np.minimum(bbox[..., 1] + bbox[..., 3], roi[..., 1] + roi[..., 3])\n",
    "\n",
    "    invalid_x = np.less(x_right, x_left)\n",
    "    invalid_y = np.less(y_bottom, y_top)\n",
    "    invalid = np.logical_or(invalid_x, invalid_y)\n",
    "\n",
    "    # The intersection of two axis-aligned bounding boxes is always an\n",
    "    # axis-aligned bounding box\n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "    intersection_area[invalid] = 0.\n",
    "    return intersection_area\n",
    "\n",
    "\n",
    "def within_roi(bbox, roi, threshold):\n",
    "    intersection_area = intersection(bbox, roi)\n",
    "    object_area = np.prod(bbox[..., 2:], -1)\n",
    "    fraction_of_object_area_in_roi = intersection_area / (object_area + 1e-8)\n",
    "    \n",
    "    objects_within_roi = np.greater(fraction_of_object_area_in_roi, threshold)\n",
    "    return objects_within_roi\n",
    "\n",
    "objects_within_roi = within_roi(objects[..., 1:], original_roi, intersection_threshold)\n",
    "objects = objects[objects_within_roi]\n",
    "\n",
    "print 'Total number of objects within ROI:', objects.shape[0]\n",
    "\n",
    "# Count objects in all remaining frames frames\n",
    "unique_frames, object_counts = np.unique(objects[..., 0], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all frames we have\n",
    "def find_frames(path):\n",
    "    frames_paths = [os.path.join(path, p) for p in os.listdir(path) if p.endswith('jpeg')]\n",
    "    frames = {int(p.split('_')[-1].split('.')[0]): p for p in frames_paths}\n",
    "    return frames\n",
    "\n",
    "frames = find_frames(frames_folder)\n",
    "frame_nums = sorted(frames.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_info = dict()\n",
    "\n",
    "object_counts = {k: v for k, v in zip(unique_frames, object_counts)}\n",
    "\n",
    "for frame_num, path in frames.iteritems():\n",
    "    frame_info[frame_num] = AttrDict()\n",
    "    if frame_num in object_counts:\n",
    "        count = object_counts[frame_num]\n",
    "    else:\n",
    "        count = 0\n",
    "        \n",
    "    frame_info[frame_num]['count'] = count\n",
    "    frame_info[frame_num]['path'] = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates sequences\n",
    "seqs = [] # a list of list of consecutive frame numbers\n",
    "\n",
    "last_frame_was_empty = None\n",
    "n_empty_frames = 0\n",
    "seq = []\n",
    "\n",
    "frame_nums = sorted(frame_info.keys())\n",
    "\n",
    "# for i, (frame_num, obj_count) in enumerate(regularly_spaced_frames_and_counts):\n",
    "for frame_num in frame_nums:\n",
    "    \n",
    "#     frame_is_invalid = (obj_count == -1)\n",
    "#     frame_is_empty = (obj_count == 0)\n",
    "    \n",
    "    frame_is_invalid = (frame_info[frame_num].count > max_n_objects)\n",
    "    frame_is_empty = (frame_info[frame_num].count == 0)\n",
    "    \n",
    "    if frame_is_invalid:\n",
    "        n_empty_frames = 0\n",
    "            \n",
    "        if len(seq) > 0:\n",
    "            seqs.append(seq)\n",
    "            seq = []\n",
    "       \n",
    "    elif frame_is_empty and len(seq) > 0:\n",
    "        if n_empty_frames < max_empty_frames:\n",
    "            n_empty_frames += 1\n",
    "            seq.append(frame_num)\n",
    "        else:\n",
    "            n_empty_frames = 0\n",
    "            seqs.append(seq)\n",
    "            seq = []\n",
    "            \n",
    "    else:\n",
    "        if len(seq) == 0:\n",
    "            if last_frame_was_empty:\n",
    "                seq.append(last_frame)\n",
    "                \n",
    "        seq.append(frame_num)\n",
    "        \n",
    "    last_frame = frame_num\n",
    "    last_frame_was_empty = frame_is_empty\n",
    "    last_frame_was_valid = not frame_is_invalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "all_valid_frames = list(itertools.chain(*seqs))\n",
    "print 'Number of valid frames', len(all_valid_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splits sequences into fixed-length ones\n",
    "fixed_length_seqs = []\n",
    "for seq in seqs:\n",
    "    if len(seq) < target_sequence_length:\n",
    "        continue\n",
    "    \n",
    "    for t in xrange(0, len(seq) + 1, target_sequence_length):\n",
    "        fixed_length_seqs.append(seq[t:t+target_sequence_length])\n",
    "        \n",
    "    if len(fixed_length_seqs[-1]) < target_sequence_length // 2:\n",
    "        del fixed_length_seqs[-1]\n",
    "\n",
    "seqs = fixed_length_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # prune sequences\n",
    "for i in xrange(len(seqs) - 1, -1, -1):\n",
    "    if len(seqs[i]) < min_seq_len:\n",
    "        del seqs[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "seq_lens = [len(seq) for seq in seqs]\n",
    "print 'Created {} sequences:'.format(len(seqs))\n",
    "print '\\tmin seq_len =', min(seq_lens)\n",
    "print '\\tmean seq_len =', np.mean(seq_lens)\n",
    "print '\\tmedian seq_len =', np.median(seq_lens)\n",
    "print '\\tmax seq_len =', max(seq_lens)\n",
    "print '\\ttotal number of frames =', sum(seq_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for every frame, figure out how many object are there\n",
    "flat_seqs = nest.flatten(seqs)\n",
    "flat_nums = [frame_info[i].count for i in flat_seqs]\n",
    "nums = nest.pack_sequence_as(seqs, flat_nums)\n",
    "print 'Average number of objects per frame =', np.mean(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "y, x, h, w = roi     \n",
    "\n",
    "for i, seq in enumerate(seqs):\n",
    "    for j, frame_num in enumerate(seq):\n",
    "\n",
    "        img = cv2.imread(frame_info[frame_num].path)\n",
    "        img = img[y:y+h, x:x+w]\n",
    "        seq[j] = img\n",
    "        \n",
    "    seqs[i] = np.asarray(seq)\n",
    "    nums[i] = np.asarray(nums[i])\n",
    "        \n",
    "seqs = np.stack(seqs, 1)\n",
    "nums = np.stack(nums, 1).astype(np.int32)[..., np.newaxis]\n",
    "print seqs.shape, nums.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pickle_to_file(path, obj):\n",
    "    with open(path, 'w') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "data = dict(\n",
    "    imgs=seqs,\n",
    "    nums=nums\n",
    ")\n",
    "\n",
    "pickle_to_file(pickle_path, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves frames of every sequence and crop stuff\n",
    "def mkdir_p(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        \n",
    "y, x, h, w = roi        \n",
    "        \n",
    "mkdir_p(seqs_folder)\n",
    "for i in xrange(seqs.shape[1]):\n",
    "    seq = seqs[:, i]\n",
    "    seq_folder = os.path.join(seqs_folder, '{:04d}'.format(i))\n",
    "    mkdir_p(seq_folder)\n",
    "    for j, img in enumerate(seq):\n",
    "        dst_img_path = os.path.join(seq_folder, '{:04d}.jpeg'.format(j))\n",
    "\n",
    "        cv2.imwrite(dst_img_path, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rect(bbox, c=None, facecolor='none', label=None, ax=None, line_width=1):\n",
    "    r = Rectangle((bbox[1], bbox[0]), bbox[3], bbox[2], linewidth=line_width,\n",
    "                  edgecolor=c, facecolor=facecolor, label=label)\n",
    "\n",
    "    if ax is not None:\n",
    "        ax.add_patch(r)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "def plot_random_frame(ax, only_roi=False):\n",
    "    \n",
    "    n_objects = 0\n",
    "    while n_objects == 0:\n",
    "        frame = np.random.choice(all_valid_frames)\n",
    "        img_path = frames[frame]\n",
    "        bboxes = objects[np.equal(objects[:, 0], frame)][:, 1:]\n",
    "        objects_within_roi = within_roi(bboxes, original_roi, intersection_threshold)\n",
    "#         print bboxes.shape[0], objects_within_roi.sum(),\n",
    "        bboxes = bboxes[objects_within_roi]\n",
    "\n",
    "        n_objects = bboxes.shape[0]\n",
    "#         print n_objects\n",
    "\n",
    "    bboxes /= ratio\n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "#     img = maybe_negate_foreground(img)\n",
    "\n",
    "    if only_roi:\n",
    "        bboxes[:, :2] -= np.asarray(roi[:2]).reshape((1, 2))\n",
    "        y, x, h, w = roi\n",
    "        img = img[y:y+h, x:x+w]\n",
    "    \n",
    "    ax.imshow(img)\n",
    "    ax.set_title('n_objects = {}'.format(n_objects))\n",
    "    if not only_roi:\n",
    "        rect(roi, c='g', ax=ax)\n",
    "\n",
    "    for bbox in bboxes:\n",
    "#         print bbox\n",
    "        rect(bbox, c='r', ax=ax)\n",
    "        \n",
    "fig, axes = plt.subplots(4, 4, figsize=(32, 18), sharex=True, sharey=True)\n",
    "for ax in axes.flatten():\n",
    "    plot_random_frame(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
